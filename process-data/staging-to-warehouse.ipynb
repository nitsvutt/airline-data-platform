{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a37dab0a",
   "metadata": {},
   "source": [
    "## 1. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d39a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df = pd.read_csv('../../flight-delay/extracted_data/mysql/db/2003.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fb4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df[[\"Cancelled\", \"CancellationCode\", \"Diverted\"]].drop_duplicates()\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df[[\"Cancelled\",\"CancellationCode\", \"Diverted\"]].drop_duplicates()\n",
    "len(df3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37536d98",
   "metadata": {},
   "source": [
    "## 2. Load and integrate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55921106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# initialize spark session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"StagingToWarehouse\") \\\n",
    "        .config(\"spark.executor.memory\", \"2g\") \\\n",
    "        .config(\"spark.executor.cores\", '2') \\\n",
    "        .config(\"spark.driver.memory\", '2g') \\\n",
    "        .config(\"spark.driver.cores\", '2') \\\n",
    "        .config(\"spark.cassandra.connection.host\", \"localhost\") \\\n",
    "        .config(\"spark.cassandra.connection.port\", \"9042\") \\\n",
    "        .config(\"spark.cassandra.auth.username\", \"root\") \\\n",
    "        .config(\"spark.cassandra.auth.password\", \"admin\") \\\n",
    "        .config(\"spark.jars\", \"../../tools/spark-jars/spark-3.2-bigquery-0.31.1.jar\") \\\n",
    "        .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "        .config(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"../../tools/bigquery/key_file.json\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0a773-defb-444b-9f3c-458381dd179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max id of fact_records table\n",
    "fact_records_max_id = spark.read \\\n",
    "                        .format(\"bigquery\") \\\n",
    "                        .options(parentProject=\"test-373705\") \\\n",
    "                        .options(table=\"flight_delay.fact_records\") \\\n",
    "                        .load().select(\"id\") \\\n",
    "                        .agg(max(\"id\")) \\\n",
    "                        .collect()[0][0]\n",
    "# ensure max id have a value\n",
    "if fact_records_max_id is None:\n",
    "    fact_records_max_id=-1\n",
    "\n",
    "# extract data from mysql table\n",
    "mysql = spark.read \\\n",
    "            .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "            .options(keyspace=\"flight_delay\") \\\n",
    "            .options(table=\"mysql\") \\\n",
    "            .load() \\\n",
    "            .filter(col(\"id\")>fact_records_max_id)\n",
    "# extract data from mongodb table\n",
    "mongodb = spark.read \\\n",
    "            .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "            .options(keyspace=\"flight_delay\") \\\n",
    "            .options(table=\"mongodb\") \\\n",
    "            .load() \\\n",
    "            .filter(col(\"id\")>fact_records_max_id)\n",
    "# integrate data, rename columns, and change datatype\n",
    "source = mysql.union(mongodb).select(\n",
    "    col(\"id\").alias(\"id\"),\n",
    "    col(\"actualelapsedtime\").cast(\"bigint\").alias(\"actual_elapsed_time\"),\n",
    "    col(\"airtime\").cast(\"bigint\").alias(\"air_time\"),\n",
    "    col(\"arrdel15\").cast(\"bigint\").alias(\"arr_delay_15\"),\n",
    "    col(\"arrdelay\").cast(\"bigint\").alias(\"arr_delay\"),\n",
    "    col(\"arrdelayminutes\").cast(\"bigint\").alias(\"arr_delay_minutes\"),\n",
    "    col(\"arrivaldelaygroups\").cast(\"bigint\").alias(\"arr_delay_groups\"),\n",
    "    col(\"arrtime\").cast(\"bigint\").alias(\"arr_time\"),\n",
    "    col(\"arrtimeblk\").alias(\"arr_time_block\"),\n",
    "    col(\"cancellationcode\").alias(\"cancellation_code\"),\n",
    "    col(\"cancelled\").cast(\"bigint\"),\n",
    "    col(\"carrierdelay\").cast(\"bigint\").alias(\"carrier_delay\"),\n",
    "    col(\"crsarrtime\").alias(\"crs_arr_time\"),\n",
    "    col(\"crsdeptime\").alias(\"crs_dep_time\"),\n",
    "    col(\"crselapsedtime\").cast(\"bigint\").alias(\"crs_elapsed_time\"),\n",
    "    col(\"dayofmonth\").alias(\"day_of_month\"),\n",
    "    col(\"dayofweek\").alias(\"day_of_week\"),\n",
    "    col(\"departuredelaygroups\").cast(\"bigint\").alias(\"dep_delay_groups\"),\n",
    "    col(\"depdel15\").cast(\"bigint\").alias(\"dep_delay_15\"),\n",
    "    col(\"depdelay\").cast(\"bigint\").alias(\"dep_delay\"),\n",
    "    col(\"depdelayminutes\").cast(\"bigint\").alias(\"dep_delay_minutes\"),\n",
    "    col(\"deptime\").cast(\"bigint\").alias(\"dep_time\"),\n",
    "    col(\"deptimeblk\").alias(\"dep_time_block\"),\n",
    "    col(\"dest\"),\n",
    "    col(\"destairportid\").alias(\"dest_airport_id\"),\n",
    "    col(\"destairportseqid\").alias(\"dest_airport_seq_id\"),\n",
    "    col(\"destcitymarketid\").alias(\"dest_city_market_id\"),\n",
    "    col(\"destcityname\").alias(\"dest_city_name\"),\n",
    "    col(\"deststate\").alias(\"dest_state\"),\n",
    "    col(\"deststatefips\").alias(\"dest_state_fips\"),\n",
    "    col(\"deststatename\").alias(\"dest_state_name\"),\n",
    "    col(\"destwac\").alias(\"dest_wac\"),\n",
    "    col(\"distance\").cast(\"bigint\"),\n",
    "    col(\"distancegroup\").alias(\"distance_group\"),\n",
    "    col(\"diverted\").cast(\"bigint\").alias(\"diverted\"),\n",
    "    col(\"dot_id_reporting_airline\"),\n",
    "    col(\"flight_number_reporting_airline\"),\n",
    "    col(\"flightdate\").cast(\"date\").alias(\"flight_date\"),\n",
    "    col(\"flights\").cast(\"bigint\"),\n",
    "    col(\"iata_code_reporting_airline\"),\n",
    "    col(\"lateaircraftdelay\").cast(\"bigint\").alias(\"late_aircraft_delay\"),\n",
    "    col(\"month\"),\n",
    "    col(\"nasdelay\").cast(\"bigint\").alias(\"nas_delay\"),\n",
    "    col(\"origin\"),\n",
    "    col(\"originairportid\").alias(\"origin_airport_id\"),\n",
    "    col(\"originairportseqid\").alias(\"origin_airport_seq_id\"),\n",
    "    col(\"origincitymarketid\").alias(\"origin_city_market_id\"),\n",
    "    col(\"origincityname\").alias(\"origin_city_name\"),\n",
    "    col(\"originstate\").alias(\"origin_state\"),\n",
    "    col(\"originstatefips\").alias(\"origin_state_fips\"),\n",
    "    col(\"originstatename\").alias(\"origin_state_name\"),\n",
    "    col(\"originwac\").alias(\"origin_wac\"),\n",
    "    col(\"quarter\"),\n",
    "    col(\"reporting_airline\"),\n",
    "    col(\"securitydelay\").cast(\"bigint\").alias(\"security_delay\"),\n",
    "    col(\"tail_number\"),\n",
    "    col(\"taxiin\").cast(\"bigint\").alias(\"taxi_in\"),\n",
    "    col(\"taxiout\").cast(\"bigint\").alias(\"taxi_out\"),\n",
    "    col(\"weatherdelay\").cast(\"bigint\").alias(\"weather_delay\"),\n",
    "    col(\"wheelsoff\").cast(\"bigint\").alias(\"wheels_on\"),\n",
    "    col(\"wheelson\").cast(\"bigint\").alias(\"wheels_off\"),\n",
    "    col(\"year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cbba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e000861c",
   "metadata": {},
   "source": [
    "## 3. dim_date table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb8888-dfe1-4730-9044-487dbcd7ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get \"key\"-\"key value\" from dim_date table\n",
    "current_dim_date = spark.read \\\n",
    "                    .format(\"bigquery\") \\\n",
    "                    .options(parentProject=\"test-373705\") \\\n",
    "                    .options(table=\"flight_delay.dim_date\") \\\n",
    "                    .load().select(\"id\", \"flight_date\")\n",
    "# get new data from source dataframe\n",
    "new_dim_date = source.select(\"year\", \"quarter\", \"month\", \"day_of_month\", \"day_of_week\", \"flight_date\").distinct()\n",
    "# mapping\n",
    "joined_dim_date = new_dim_date.join(current_dim_date, on=\"flight_date\", how=\"full\")\n",
    "# fullfill null id\n",
    "dim_date = joined_dim_date.filter(col(\"id\").isNull()) \\\n",
    "                    .orderBy(col(\"flight_date\").asc()) \\\n",
    "                    .withColumn(\"id\", monotonically_increasing_id())\n",
    "# add date_id to source dataframe\n",
    "date_id_source = source.join(dim_date.selectExpr(\"flight_date\", \"id as date_id\"),\n",
    "                             on=\"flight_date\",\n",
    "                             how=\"left\")\n",
    "# get max id of dim_date table\n",
    "max_date_id = current_dim_date.agg(max(\"id\")).collect()[0][0]\n",
    "# ensure max id have a value\n",
    "if max_date_id is None:\n",
    "    max_date_id=-1\n",
    "# drop old data\n",
    "to_append_dim_date = dim_date.filter(col(\"id\")>max_date_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264cda53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append new data to dim_date table\n",
    "to_append_dim_date.orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"bigquery\") \\\n",
    "            .options(parentProject=\"test-373705\") \\\n",
    "            .options(table=\"flight_delay.dim_date\") \\\n",
    "            .option(\"writeMethod\", \"direct\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a235e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export new data to csv\n",
    "to_append_dim_date.select(\"id\", \"year\", \"quarter\", \"month\", \"day_of_month\", \"day_of_week\", \"flight_date\") \\\n",
    "            .repartition(1) \\\n",
    "            .orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"csv\") \\\n",
    "            .options(header=\"True\") \\\n",
    "            .save(\"../../flight-delay/bigquery/dim_date\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b90ad2f9",
   "metadata": {},
   "source": [
    "## 4. dim_airline table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32865ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get \"key\"-\"key value\" from dim_airline table\n",
    "current_dim_airline = spark.read \\\n",
    "                    .format(\"bigquery\") \\\n",
    "                    .options(parentProject=\"test-373705\") \\\n",
    "                    .options(table=\"flight_delay.dim_airline\") \\\n",
    "                    .load().select(\"id\", \"reporting_airline\", \"tail_number\", \"flight_number_reporting_airline\")\n",
    "# get new data from date_id_source dataframe\n",
    "new_dim_airline = date_id_source.select(\"reporting_airline\", \"dot_id_reporting_airline\",\n",
    "                                            \"iata_code_reporting_airline\", \"tail_number\",\n",
    "                                            \"flight_number_reporting_airline\").distinct()\n",
    "# mapping\n",
    "joined_dim_airline = new_dim_airline.join(current_dim_airline,\n",
    "                                       on=[\"reporting_airline\", \"tail_number\", \"flight_number_reporting_airline\"],\n",
    "                                       how=\"full\")\n",
    "# fullfill null id\n",
    "dim_airline = joined_dim_airline.filter(col(\"id\").isNull()) \\\n",
    "                    .orderBy(col(\"reporting_airline\").asc(),\n",
    "                             col(\"tail_number\").asc(),\n",
    "                             col(\"flight_number_reporting_airline\").asc()) \\\n",
    "                    .withColumn(\"id\", monotonically_increasing_id())\n",
    "# add airline_id to date_id_source dataframe\n",
    "airline_id_source = date_id_source.join(dim_airline.selectExpr(\"reporting_airline\", \"tail_number\",\n",
    "                                                               \"flight_number_reporting_airline\", \"id as airline_id\"),\n",
    "                                        on=[\"reporting_airline\", \"tail_number\", \"flight_number_reporting_airline\"],\n",
    "                                        how=\"left\")\n",
    "# get max id of dim_airline table\n",
    "max_airline_id = current_dim_airline.agg(max(\"id\")).collect()[0][0]\n",
    "# ensure max id have a value\n",
    "if max_airline_id is None:\n",
    "    max_airline_id=-1\n",
    "# drop old data\n",
    "to_append_dim_airline = dim_airline.filter(col(\"id\")>max_airline_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f09b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append new data to dim_airline table\n",
    "to_append_dim_airline.orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"bigquery\") \\\n",
    "            .options(parentProject=\"test-373705\") \\\n",
    "            .options(table=\"flight_delay.dim_airline\") \\\n",
    "            .option(\"writeMethod\", \"direct\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39571a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export new data to csv\n",
    "to_append_dim_airline.select(\"id\", \"reporting_airline\", \"dot_id_reporting_airline\", \"iata_code_reporting_airline\",\n",
    "                             \"tail_number\", \"flight_number_reporting_airline\") \\\n",
    "            .repartition(1) \\\n",
    "            .orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"csv\") \\\n",
    "            .options(header=\"True\") \\\n",
    "            .save(\"../../flight-delay/bigquery/dim_airline\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eef5bc55",
   "metadata": {},
   "source": [
    "## 5. dim_origin table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get \"key\"-\"key value\" from dim_origin table\n",
    "current_dim_origin = spark.read \\\n",
    "                    .format(\"bigquery\") \\\n",
    "                    .options(parentProject=\"test-373705\") \\\n",
    "                    .options(table=\"flight_delay.dim_origin\") \\\n",
    "                    .load().select(\"id\", \"origin_airport_id\")\n",
    "# get new data from airline_id_source dataframe\n",
    "new_dim_origin = airline_id_source.select(\"origin_airport_id\", \"origin_airport_seq_id\", \"origin_city_market_id\",\n",
    "                               \"origin\", \"origin_city_name\", \"origin_state\", \"origin_state_fips\",\n",
    "                              \"origin_state_name\", \"origin_wac\").distinct()\n",
    "# mapping\n",
    "joined_dim_origin = new_dim_origin.join(current_dim_origin, on=\"origin_airport_id\", how=\"full\")\n",
    "# fullfill null id\n",
    "dim_origin = joined_dim_origin.filter(col(\"id\").isNull()) \\\n",
    "                    .orderBy(col(\"origin_airport_id\").asc()) \\\n",
    "                    .withColumn(\"id\", monotonically_increasing_id())\n",
    "# add origin_id to airline_id_source dataframe\n",
    "origin_id_source = airline_id_source.join(dim_origin.selectExpr(\"origin_airport_id\", \"id as origin_id\"),\n",
    "                             on=\"origin_airport_id\",\n",
    "                             how=\"left\")\n",
    "# get max id of dim_origin table\n",
    "max_origin_id = current_dim_origin.agg(max(\"id\")).collect()[0][0]\n",
    "# ensure max id have a value\n",
    "if max_origin_id is None:\n",
    "    max_origin_id=-1\n",
    "# drop old data\n",
    "to_append_dim_origin = dim_origin.filter(col(\"id\")>max_origin_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae19eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append new data to dim_origin table\n",
    "to_append_dim_origin.orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"bigquery\") \\\n",
    "            .options(parentProject=\"test-373705\") \\\n",
    "            .options(table=\"flight_delay.dim_origin\") \\\n",
    "            .option(\"writeMethod\", \"direct\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ada5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export new data to csv\n",
    "to_append_dim_origin.select(\"id\", \"origin_airport_id\", \"origin_airport_seq_id\", \"origin_city_market_id\",\n",
    "                             \"origin\", \"origin_city_name\", \"origin_state\", \"origin_state_fips\",\n",
    "                             \"origin_state_name\", \"origin_wac\") \\\n",
    "            .repartition(1) \\\n",
    "            .orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"csv\") \\\n",
    "            .options(header=\"True\") \\\n",
    "            .save(\"../../flight-delay/bigquery/dim_origin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ddb3b39",
   "metadata": {},
   "source": [
    "## 6. dim_destination table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e0e6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get \"key\"-\"key value\" from dim_destination table\n",
    "current_dim_destination = spark.read \\\n",
    "                    .format(\"bigquery\") \\\n",
    "                    .options(parentProject=\"test-373705\") \\\n",
    "                    .options(table=\"flight_delay.dim_destination\") \\\n",
    "                    .load().select(\"id\", \"dest_airport_id\")\n",
    "# get new data from origin_id_source dataframe\n",
    "new_dim_destination = origin_id_source.select(\"dest_airport_id\", \"dest_airport_seq_id\", \"dest_city_market_id\",\n",
    "                               \"dest\", \"dest_city_name\", \"dest_state\", \"dest_state_fips\",\n",
    "                              \"dest_state_name\", \"dest_wac\").distinct()\n",
    "# mapping\n",
    "joined_dim_destination = new_dim_destination.join(current_dim_destination, on=\"dest_airport_id\", how=\"full\")\n",
    "# fullfill null id\n",
    "dim_destination = joined_dim_destination.filter(col(\"id\").isNull()) \\\n",
    "                    .orderBy(col(\"dest_airport_id\").asc()) \\\n",
    "                    .withColumn(\"id\", monotonically_increasing_id())\n",
    "# add destination_id to origin_id_source dataframe\n",
    "destination_id_source = origin_id_source.join(dim_destination.selectExpr(\"dest_airport_id\", \"id as destination_id\"),\n",
    "                             on=\"dest_airport_id\",\n",
    "                             how=\"left\")\n",
    "# get max id of dim_destination table\n",
    "max_destination_id = current_dim_destination.agg(max(\"id\")).collect()[0][0]\n",
    "# ensure max id have a value\n",
    "if max_destination_id is None:\n",
    "    max_destination_id=-1\n",
    "# drop old data\n",
    "to_append_dim_destination = dim_destination.filter(col(\"id\")>max_destination_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6938063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append new data to dim_destination table\n",
    "to_append_dim_destination.orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"bigquery\") \\\n",
    "            .options(parentProject=\"test-373705\") \\\n",
    "            .options(table=\"flight_delay.dim_destination\") \\\n",
    "            .option(\"writeMethod\", \"direct\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export new data to csv\n",
    "to_append_dim_destination.select(\"id\", \"dest_airport_id\", \"dest_airport_seq_id\", \"dest_city_market_id\",\n",
    "                             \"dest\", \"dest_city_name\", \"dest_state\", \"dest_state_fips\",\n",
    "                             \"dest_state_name\", \"dest_wac\") \\\n",
    "            .repartition(1) \\\n",
    "            .orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"csv\") \\\n",
    "            .options(header=\"True\") \\\n",
    "            .save(\"../../flight-delay/bigquery/dim_destination\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2aba2ab9",
   "metadata": {},
   "source": [
    "## 7. dim_schedule table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get \"key\"-\"key value\" from dim_schedule table\n",
    "current_dim_schedule = spark.read \\\n",
    "                    .format(\"bigquery\") \\\n",
    "                    .options(parentProject=\"test-373705\") \\\n",
    "                    .options(table=\"flight_delay.dim_schedule\") \\\n",
    "                    .load().select(\"id\", \"crs_dep_time\", \"crs_arr_time\", \"crs_elapsed_time\", \"distance\")\n",
    "# get new data from destination_id_source dataframe\n",
    "new_dim_schedule = destination_id_source.select(\"crs_dep_time\", \"dep_time_block\", \"crs_arr_time\",\n",
    "                               \"arr_time_block\", \"crs_elapsed_time\", \"distance\", \"distance_group\").distinct()\n",
    "# mapping\n",
    "joined_dim_schedule = new_dim_schedule.join(current_dim_schedule,\n",
    "                                            on=[\"crs_dep_time\", \"crs_arr_time\", \"crs_elapsed_time\", \"distance\"],\n",
    "                                            how=\"full\")\n",
    "# fullfill null id\n",
    "dim_schedule = joined_dim_schedule.filter(col(\"id\").isNull()) \\\n",
    "                    .orderBy(col(\"crs_dep_time\").asc(),\n",
    "                            col(\"crs_arr_time\").asc(),\n",
    "                            col(\"crs_elapsed_time\").asc(),\n",
    "                            col(\"distance\").asc()) \\\n",
    "                    .withColumn(\"id\", monotonically_increasing_id())\n",
    "# add schedule_id to destination_id_source dataframe\n",
    "schedule_id_source = destination_id_source.join(dim_schedule.selectExpr(\"crs_dep_time\", \"crs_arr_time\",\n",
    "                                                                         \"crs_elapsed_time\", \"distance\",\n",
    "                                                                         \"id as schedule_id\"),\n",
    "                             on=[\"crs_dep_time\", \"crs_arr_time\", \"crs_elapsed_time\", \"distance\"],\n",
    "                             how=\"left\")\n",
    "# get max id of dim_schedule table\n",
    "max_schedule_id = current_dim_schedule.agg(max(\"id\")).collect()[0][0]\n",
    "# ensure max id have a value\n",
    "if max_schedule_id is None:\n",
    "    max_schedule_id=-1\n",
    "# drop old data\n",
    "to_append_dim_schedule = dim_schedule.filter(col(\"id\")>max_schedule_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da05ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append new data to dim_schedule table\n",
    "to_append_dim_schedule.orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"bigquery\") \\\n",
    "            .options(parentProject=\"test-373705\") \\\n",
    "            .options(table=\"flight_delay.dim_schedule\") \\\n",
    "            .option(\"writeMethod\", \"direct\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f73b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export new data to csv\n",
    "to_append_dim_schedule.select(\"id\", \"crs_dep_time\", \"dep_time_block\", \"crs_arr_time\",\n",
    "                    \"arr_time_block\", \"crs_elapsed_time\", \"distance\", \"distance_group\") \\\n",
    "            .repartition(1) \\\n",
    "            .orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"csv\") \\\n",
    "            .options(header=\"True\") \\\n",
    "            .save(\"../../flight-delay/bigquery/dim_schedule\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "664d7dae",
   "metadata": {},
   "source": [
    "## 8. dim_cancellations_and_diversions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534da5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get \"key\"-\"key value\" from dim_cancellations_and_diversions table\n",
    "current_dim_cad = spark.read \\\n",
    "                    .format(\"bigquery\") \\\n",
    "                    .options(parentProject=\"test-373705\") \\\n",
    "                    .options(table=\"flight_delay.dim_cancellations_and_diversions\") \\\n",
    "                    .load().select(\"id\", \"cancelled\", \"cancellation_code\", \"diverted\")\n",
    "# get new data from schedule_id_source dataframe\n",
    "new_dim_cad = schedule_id_source.select(\"cancelled\", \"cancellation_code\", \"diverted\").distinct()\n",
    "# mapping\n",
    "joined_dim_cad = new_dim_cad.join(current_dim_cad,\n",
    "                                  on=[\"cancelled\", \"cancellation_code\", \"diverted\"],\n",
    "                                  how=\"full\")\n",
    "# fullfill null id\n",
    "dim_cad = joined_dim_cad.filter(col(\"id\").isNull()) \\\n",
    "                    .orderBy(col(\"cancelled\").asc(),\n",
    "                            col(\"cancellation_code\").asc(),\n",
    "                            col(\"diverted\").asc()) \\\n",
    "                    .withColumn(\"id\", monotonically_increasing_id())\n",
    "# add cancellations_and_diversions_id to schedule_id_source dataframe\n",
    "completed_source = schedule_id_source.join(dim_cad.selectExpr(\"cancelled\", \"cancellation_code\",\"diverted\",\n",
    "                                                                     \"id as cancellations_and_diversions_id\"),\n",
    "                                           on=[\"cancelled\", \"cancellation_code\", \"diverted\"],\n",
    "                                           how=\"left\")\n",
    "# get max id of dim_cancellations_and_diversions table\n",
    "max_cad_id = current_dim_cad.agg(max(\"id\")).collect()[0][0]\n",
    "# ensure max id have a value\n",
    "if max_cad_id is None:\n",
    "    max_cad_id=-1\n",
    "# drop old data\n",
    "to_append_dim_cad = dim_cad.filter(col(\"id\")>max_cad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd14267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append new data to dim_cancellations_and_diversions table\n",
    "to_append_dim_cad.orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"bigquery\") \\\n",
    "            .options(parentProject=\"test-373705\") \\\n",
    "            .options(table=\"flight_delay.dim_cancellations_and_diversions\") \\\n",
    "            .option(\"writeMethod\", \"direct\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa63d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export new data to csv\n",
    "to_append_dim_cad.select(\"id\", \"cancelled\", \"cancellation_code\",\"diverted\") \\\n",
    "            .repartition(1) \\\n",
    "            .orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"csv\") \\\n",
    "            .options(header=\"True\") \\\n",
    "            .save(\"../../flight-delay/bigquery/dim_cancellations_and_diversions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6d0b17e",
   "metadata": {},
   "source": [
    "## 9. fact_records table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3fc3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select necessary columns for fact_records table\n",
    "fact_records = completed_source.select(\"id\", \"date_id\", \"airline_id\", \"origin_id\", \"destination_id\", \"schedule_id\",\n",
    "                                      \"cancellations_and_diversions_id\", \"dep_time\", \"dep_delay\", \"dep_delay_minutes\",\n",
    "                                      \"dep_delay_15\", \"dep_delay_groups\", \"taxi_out\", \"taxi_in\", \"wheels_off\",\n",
    "                                      \"wheels_on\", \"arr_time\", \"arr_delay\", \"arr_delay_minutes\", \"arr_delay_15\",\n",
    "                                      \"arr_delay_groups\", \"actual_elapsed_time\", \"air_time\", \"flights\",\n",
    "                                      \"carrier_delay\", \"weather_delay\", \"nas_delay\", \"security_delay\",\n",
    "                                       \"late_aircraft_delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd21acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append new data to fact_records table\n",
    "fact_records.orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"bigquery\") \\\n",
    "            .options(parentProject=\"test-373705\") \\\n",
    "            .options(table=\"flight_delay.fact_records\") \\\n",
    "            .option(\"writeMethod\", \"direct\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export new data to csv\n",
    "fact_records.repartition(2) \\\n",
    "            .orderBy(col(\"id\").asc()) \\\n",
    "            .write \\\n",
    "            .format(\"csv\") \\\n",
    "            .options(header=\"True\") \\\n",
    "            .save(\"../../flight-delay/bigquery/fact_records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f79e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
